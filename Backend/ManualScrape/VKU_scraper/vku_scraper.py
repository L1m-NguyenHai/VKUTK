"""
VKU Scraper Module - Pure Functions
Ch·ª©a t·∫•t c·∫£ logic scrape, kh√¥ng c√≥ dependency v√†o main
"""

from playwright.sync_api import sync_playwright, Page, BrowserContext
import json
import os
import time
import re
from typing import Dict, List, Optional, Any

# ---------- Session Management ----------

def save_session(context: BrowserContext, session_file: str = "session.json") -> None:
    """L∆∞u session cookies v√†o file"""
    try:
        cookies = context.cookies()
        with open(session_file, "w", encoding="utf-8") as f:
            json.dump(cookies, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ Session saved to {session_file}")
    except Exception as e:
        print(f"‚ùå L·ªói khi l∆∞u session: {e}")

def load_session(context: BrowserContext, session_file: str = "session.json") -> bool:
    """Load session cookies t·ª´ file"""
    try:
        if not os.path.exists(session_file):
            print(f"‚ö†Ô∏è Session file kh√¥ng t·ªìn t·∫°i: {session_file}")
            return False
        
        with open(session_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        # Handle c·∫£ 2 format: direct array ho·∫∑c object v·ªõi "cookies" key
        cookies = data["cookies"] if isinstance(data, dict) and "cookies" in data else data
        context.add_cookies(cookies)
        print(f"‚úÖ Session loaded from {session_file}")
        return True
    except Exception as e:
        print(f"‚ùå L·ªói khi load session: {e}")
        return False

# ---------- Login & Auth ----------

def login_with_browser(profile_url: str = "https://daotao.vku.udn.vn/sv/hoso") -> None:
    """M·ªü browser ƒë·ªÉ user ƒëƒÉng nh·∫≠p Google"""
    print("\nüîê Vui l√≤ng ƒëƒÉng nh·∫≠p b·∫±ng Google...")
    print("üëâ Sau khi ƒëƒÉng nh·∫≠p th√†nh c√¥ng, nh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
    input()

# ---------- Crawl Th√¥ng tin c√° nh√¢n ----------

def crawl_student_info(page: Page) -> Dict[str, str]:
    """
    L·∫•y th√¥ng tin c√° nh√¢n sinh vi√™n t·ª´ profile page
    
    Returns:
        {
            "StudentID": "...",
            "ho_va_ten": "...",
            "lop": "...",
            "khoa_hoc": "...",
            "chuyen_nganh": "...",
            "khoa": "..."
        }
    """
    info = {}
    try:
        # Wait for page load
        page.wait_for_selector("div.profile-usertitle", timeout=20000)
        time.sleep(2)
        
        # Extract info
        info["ho_va_ten"] = page.query_selector("div.profile-usertitle-name").inner_text().strip()
        info["StudentID"] = page.query_selector("div.profile-usertitle-job").inner_text().replace("M√É SV:", "").strip()
        info["lop"] = page.query_selector("div.profile-usertitle-job + div").inner_text().replace("L·ªöP:", "").strip()
        info["khoa_hoc"] = page.query_selector("div.profile-usertitle-job + div + div").inner_text().replace("KH√ìA:", "").strip()
        info["chuyen_nganh"] = page.query_selector("div.profile-usertitle-job + div + div + div").inner_text().strip()
        info["khoa"] = page.query_selector("div.profile-usertitle-job + div + div + div + div").inner_text().strip()
        
        print(f"‚úÖ L·∫•y th√¥ng tin SV: {info['StudentID']} - {info['ho_va_ten']}")
        return info
    except Exception as e:
        print(f"‚ùå L·ªói khi l·∫•y th√¥ng tin: {e}")
        return {}

# ---------- Crawl ƒêi·ªÉm ----------

def crawl_student_grades(page: Page) -> List[Dict[str, Any]]:
    """
    L·∫•y danh s√°ch ƒëi·ªÉm t·ª´ trang ƒëi·ªÉm
    
    Returns:
        [
            {
                "TenHocPhan": "...",
                "SoTC": 3,
                "DiemT10": 8.5,
                "HocKy": "H·ªçc k·ª≥ 1"
            },
            ...
        ]
    """
    print("üîç ƒêang tr√≠ch xu·∫•t d·ªØ li·ªáu ƒëi·ªÉm...")
    
    try:
        page.wait_for_selector("table", timeout=20000)
        time.sleep(3)
        
        rows = page.locator("table tr.even.pointer")
        data = []
        hoc_ky = ""
        
        for i in range(rows.count()):
            row = rows.nth(i)
            cols = row.locator("td")
            
            if cols.count() >= 10:
                try:
                    ten_hp = cols.nth(1).inner_text().strip()
                    
                    # N·∫øu l√† d√≤ng h·ªçc k·ª≥, c·∫≠p nh·∫≠t hoc_ky
                    if "H·ªçc k·ª≥" in ten_hp:
                        hoc_ky = ten_hp
                        continue
                    
                    so_tc_str = cols.nth(2).inner_text().strip()
                    diem_t10_str = cols.nth(8).inner_text().strip()
                    
                    # Parse s·ªë TC
                    try:
                        so_tc = int(so_tc_str) if so_tc_str.isdigit() else 0
                    except:
                        so_tc = 0
                    
                    # Parse ƒëi·ªÉm T10
                    try:
                        if diem_t10_str and diem_t10_str != "ch∆∞a c√≥" and diem_t10_str != "":
                            diem_t10 = float(diem_t10_str)
                        else:
                            diem_t10 = None
                    except:
                        diem_t10 = None
                    
                    # Quy ƒë·ªïi n·∫øu l√† H·ªçc k·ª≥ ri√™ng
                    if "H·ªçc k·ª≥ ri√™ng - Quy ƒë·ªïi" in hoc_ky and diem_t10 is None:
                        diem_t10 = 10.0
                    
                    data.append({
                        "TenHocPhan": ten_hp,
                        "SoTC": so_tc,
                        "DiemT10": diem_t10,
                        "HocKy": hoc_ky
                    })
                except Exception as e:
                    print(f"‚ö†Ô∏è L·ªói khi ƒë·ªçc d√≤ng {i}: {e}")
        
        print(f"‚úÖ ƒê√£ l·∫•y {len(data)} m√¥n h·ªçc.")
        return data
    except Exception as e:
        print(f"‚ùå L·ªói khi l·∫•y ƒëi·ªÉm: {e}")
        return []

# ---------- Crawl Ti·∫øn ƒë·ªô h·ªçc t·∫≠p ----------

def crawl_tien_do_hoc_tap(page: Page) -> List[Dict[str, Any]]:
    """
    L·∫•y ti·∫øn ƒë·ªô h·ªçc t·∫≠p (l·ªô tr√¨nh h·ªçc c·ªßa sinh vi√™n)
    
    HTML Structure:
    <tr>
      <td>#STT</td>                               # C·ªôt 0
      <td>T√™n h·ªçc ph·∫ßn</td>                      # C·ªôt 1
      <td>H·ªçc k·ª≥</td>                            # C·ªôt 2
      <td>B·∫Øt bu·ªôc (checkbox ho·∫∑c <code>HP T·ª± ch·ªçn</code>)</td>  # C·ªôt 3
      <td>S·ªë TC (in <b><code>N</code></b>)</td>  # C·ªôt 4
      <td>T√¨nh tr·∫°ng + ƒêi·ªÉm</td>                 # C·ªôt 5
    </tr>
    
    Returns:
        [
            {
                "TenHocPhan": "...",
                "HocKy": "1",
                "BatBuoc": 1 or 0,
                "SoTC": "3",
                "DiemT4": 4 (int) ho·∫∑c None,
                "DiemChu": "A" ho·∫∑c None
            },
            ...
        ]
    """
    print("üîç ƒêang tr√≠ch xu·∫•t d·ªØ li·ªáu ti·∫øn ƒë·ªô h·ªçc t·∫≠p...")
    
    try:
        page.wait_for_selector("table.jambo_table tbody tr", timeout=20000)
        time.sleep(2)
        
        rows = page.locator("table.jambo_table tbody tr")
        data = []
        
        for i in range(rows.count()):
            try:
                row = rows.nth(i)
                cols = row.locator("td")
                
                if cols.count() < 6:
                    continue
                
                # C·ªôt 1: T√™n h·ªçc ph·∫ßn
                ten_hp = cols.nth(1).inner_text().strip()
                if not ten_hp:
                    continue
                
                # C·ªôt 2: H·ªçc k·ª≥
                hoc_ky = cols.nth(2).inner_text().strip()
                
                # C·ªôt 3: B·∫Øt bu·ªôc (checkbox ho·∫∑c <code>HP T·ª± ch·ªçn</code>)
                col3_html = cols.nth(3).inner_html()
                if "HP T·ª± ch·ªçn" in col3_html:
                    bat_buoc = 0  # HP t·ª± ch·ªçn = kh√¥ng b·∫Øt bu·ªôc
                else:
                    # Ki·ªÉm tra checkbox
                    checkbox_elem = cols.nth(3).locator("input[type='checkbox'][checked]")
                    bat_buoc = 1 if checkbox_elem.count() > 0 else 0
                
                # C·ªôt 4: S·ªë TC (lo·∫°i b·ªè HTML tags)
                so_tc_html = cols.nth(4).inner_html()
                so_tc = re.sub(r'<[^>]+>', '', so_tc_html).strip()
                
                # C·ªôt 5: T√¨nh tr·∫°ng + ƒêi·ªÉm
                status_html = cols.nth(5).inner_html()
                status_text = cols.nth(5).inner_text().strip()
                
                diem_t4 = None
                diem_chu = None
                
                if "Ch∆∞a h·ªçc" not in status_text and "Ch∆∞a h·ªçc" not in status_html:
                    # ƒê√£ h·ªçc - extract ƒëi·ªÉm
                    
                    # Extract DiemT4 - t√¨m s·ªë trong <code> sau "ƒêi·ªÉm T4"
                    t4_match = re.search(r'ƒêi·ªÉm T4:.*?<code>(\d+)</code>', status_html, re.DOTALL)
                    if t4_match:
                        try:
                            diem_t4 = int(t4_match.group(1))
                        except:
                            diem_t4 = None
                    
                    # Extract DiemChu - t√¨m A-F trong <code> sau "ƒêi·ªÉm ch·ªØ"
                    chu_match = re.search(r'ƒêi·ªÉm ch·ªØ:\s*<code>([A-F])</code>', status_html)
                    if chu_match:
                        diem_chu = chu_match.group(1)
                
                data.append({
                    "TenHocPhan": ten_hp,
                    "HocKy": hoc_ky,
                    "BatBuoc": bat_buoc,
                    "SoTC": so_tc,
                    "DiemT4": diem_t4,
                    "DiemChu": diem_chu
                })
                
            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói khi ƒë·ªçc d√≤ng {i}: {e}")
                continue
        
        print(f"‚úÖ ƒê√£ l·∫•y {len(data)} h·ªçc ph·∫ßn ti·∫øn ƒë·ªô h·ªçc t·∫≠p.")
        return data
        
    except Exception as e:
        print(f"‚ùå L·ªói khi l·∫•y ti·∫øn ƒë·ªô h·ªçc t·∫≠p: {e}")
        return []

# ---------- Crawl ƒêi·ªÉm T·ªïng k·∫øt ----------

def crawl_grades_summary(page: Page) -> List[Dict[str, Any]]:
    """
    L·∫•y b·∫£ng t·ªïng k·∫øt ƒëi·ªÉm theo h·ªçc k·ª≥ (future use)
    
    Returns:
        [
            {
                "HocKy": "H·ªçc k·ª≥ 1",
                "DiemT4": 3.5,
                "DiemT10": 8.75,
                "XepLoai": "Gi·ªèi",
                "SoTC": 20
            },
            ...
        ]
    """
    print("üîç ƒêang tr√≠ch xu·∫•t d·ªØ li·ªáu t·ªïng k·∫øt...")
    
    try:
        page.wait_for_selector("table", timeout=20000)
        time.sleep(3)
        
        rows = page.locator("table tr.even.pointer")
        data = []
        
        for i in range(rows.count()):
            row = rows.nth(i)
            cols = row.locator("td")
            
            if cols.count() >= 12:
                try:
                    hoc_ky = cols.nth(1).inner_text().strip()
                    
                    # Skip n·∫øu kh√¥ng ph·∫£i d√≤ng h·ªçc k·ª≥
                    if not hoc_ky.startswith("H·ªçc k·ª≥"):
                        continue
                    
                    diem_4 = cols.nth(4).inner_text().strip()
                    diem_10 = cols.nth(5).inner_text().strip()
                    xep_loai = cols.nth(8).inner_text().strip()
                    tc_tich_luy = cols.nth(11).inner_text().strip()
                    
                    data.append({
                        "HocKy": hoc_ky,
                        "DiemT4": float(diem_4) if diem_4 else None,
                        "DiemT10": float(diem_10) if diem_10 else None,
                        "XepLoai": xep_loai,
                        "SoTC": int(tc_tich_luy) if tc_tich_luy.isdigit() else 0
                    })
                except Exception as e:
                    print(f"‚ö†Ô∏è L·ªói khi ƒë·ªçc d√≤ng {i}: {e}")
        
        print(f"‚úÖ ƒê√£ l·∫•y {len(data)} h·ªçc k·ª≥ t·ªïng k·∫øt.")
        return data
    except Exception as e:
        print(f"‚ùå L·ªói khi l·∫•y t·ªïng k·∫øt: {e}")
        return []

# ---------- Main Scraper Function ----------

def scrape_vku_data(
    headless: bool = False,
    session_file: str = "session.json"
) -> Optional[Dict[str, Any]]:
    """
    Main function - Scrape t·∫•t c·∫£ d·ªØ li·ªáu t·ª´ VKU
    
    Args:
        headless: N·∫øu True, ch·∫°y ·∫©n browser
        session_file: Path ƒë·∫øn file session
    
    Returns:
        {
            "student_info": {...},
            "grades": [...],
            "summary": [...],
            "success": True
        }
    """
    print("=" * 60)
    print("üöÄ VKU SCRAPER - L·∫§Y D·ªÆ LI·ªÜU")
    print("=" * 60)
    
    profile_url = "https://daotao.vku.udn.vn/sv/hoso"
    diem_url = "https://daotao.vku.udn.vn/sv/diem"
    
    result = {
        "student_info": {},
        "grades": [],
        "summary": [],
        "success": False
    }
    
    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=headless)
            context = browser.new_context()
            
            # Load ho·∫∑c t·∫°o session m·ªõi
            if not load_session(context, session_file):
                print("\n‚ö†Ô∏è Session m·ªõi - Y√™u c·∫ßu ƒëƒÉng nh·∫≠p")
                page = context.new_page()
                page.goto(profile_url)
                login_with_browser(profile_url)
                save_session(context, session_file)
            
            # Crawl th√¥ng tin c√° nh√¢n
            print("\nüìã ƒêang l·∫•y th√¥ng tin c√° nh√¢n...")
            page = context.new_page()
            page.goto(profile_url)
            student_info = crawl_student_info(page)
            
            if not student_info:
                print("‚ùå Kh√¥ng l·∫•y ƒë∆∞·ª£c th√¥ng tin sinh vi√™n!")
                browser.close()
                return result
            
            result["student_info"] = student_info
            
            # Crawl ƒëi·ªÉm
            print("\nüìä ƒêang l·∫•y d·ªØ li·ªáu ƒëi·ªÉm...")
            page.goto(diem_url)
            grades = crawl_student_grades(page)
            result["grades"] = grades
            
            # Crawl ti·∫øn ƒë·ªô h·ªçc t·∫≠p
            print("\nüìà ƒêang l·∫•y d·ªØ li·ªáu ti·∫øn ƒë·ªô h·ªçc t·∫≠p...")
            tien_do_url = "https://daotao.vku.udn.vn/sv/hoc-phan-con-lai"
            page.goto(tien_do_url)
            tien_do = crawl_tien_do_hoc_tap(page)
            result["tien_do"] = tien_do
            
            # Crawl t·ªïng k·∫øt (n·∫øu c·∫ßn)
            print("\nüìã ƒêang l·∫•y d·ªØ li·ªáu t·ªïng k·∫øt...")
            summary = crawl_grades_summary(page)
            result["summary"] = summary
            
            result["success"] = True
            
            print("\n" + "=" * 60)
            print("‚úÖ SCRAPE TH√ÄNH C√îNG!")
            print(f"  - Student: {student_info.get('StudentID')}")
            print(f"  - Grades: {len(grades)} m√¥n")
            print(f"  - Ti·∫øn ƒë·ªô: {len(tien_do)} h·ªçc ph·∫ßn")
            print(f"  - Summary: {len(summary)} h·ªçc k·ª≥")
            print("=" * 60)
            
            browser.close()
            
    except Exception as e:
        print(f"\n‚ùå L·ªói: {e}")
    
    return result

# ---------- Utility Functions ----------

def validate_student_info(info: Dict[str, str]) -> bool:
    """Ki·ªÉm tra th√¥ng tin sinh vi√™n h·ª£p l·ªá"""
    required_fields = ["StudentID", "ho_va_ten", "lop", "khoa"]
    for field in required_fields:
        if not info.get(field):
            print(f"‚ùå Thi·∫øu field: {field}")
            return False
    return True

def validate_grades(grades: List[Dict[str, Any]]) -> bool:
    """Ki·ªÉm tra d·ªØ li·ªáu ƒëi·ªÉm h·ª£p l·ªá"""
    if not grades:
        print("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒëi·ªÉm")
        return False
    
    for grade in grades:
        if not grade.get("TenHocPhan") or not grade.get("HocKy"):
            print(f"‚ùå D·ªØ li·ªáu ƒëi·ªÉm kh√¥ng h·ª£p l·ªá: {grade}")
            return False
    
    return True
